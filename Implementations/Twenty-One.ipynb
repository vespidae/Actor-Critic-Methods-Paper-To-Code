{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33c05006-555a-4363-83ef-f4d0bfb6169d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.2000, 4.0000])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "m = torch.Tensor([2.2,4.0],)\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1e3e4e6-f2b5-4ec9-9ee9-d9ea9370e3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize policy to be evaluated\n",
    "class Agent():\n",
    "    def __init__(self, gamma=0.99):\n",
    "        #discount factor\n",
    "        self.gamma = gamma\n",
    "        #estimates of states' values\n",
    "        self.V = {}\n",
    "        #state/action spaces\n",
    "        self.spaces = {\n",
    "            #possible sums of cards\n",
    "            \"sum\":[i for i in range(4,22)],\n",
    "            #possible cards in dealer's hand\n",
    "            \"dealer_show_card\":[i+1 for i in range(10)],\n",
    "            #useable ace?\n",
    "            \"ace_eleven\":[False,True],\n",
    "            #hit (or stay)?\n",
    "            \"hit\":[0,1]\n",
    "        }\n",
    "        #combinations of parameters\n",
    "        self.state_space = []\n",
    "        #returns\n",
    "        self.reward = {}\n",
    "        #has agent visited state before?\n",
    "        self.states_visited = {}\n",
    "        #states already encountered/returns received\n",
    "        self.memory = []\n",
    "        \n",
    "        self.init_vals()\n",
    "        \n",
    "    def init_vals(self):\n",
    "        for total in self.spaces[\"sum\"]:\n",
    "            for card in self.spaces[\"dealer_show_card\"]:\n",
    "                for ace in self.spaces[\"ace_eleven\"]:\n",
    "                    self.V[(total, card, ace)] = 0\n",
    "                    self.reward[(total, card, ace)] = []\n",
    "                    self.states_visited[(total, card, ace)] = 0\n",
    "                    self.state_space.append((total, card, ace))\n",
    "                    \n",
    "    def policy(self, state):\n",
    "        total, _, _ = state\n",
    "        action = 0 if total >= 20 else 1\n",
    "        return action\n",
    "        \n",
    "    def update_V(self):\n",
    "        for idt, (state, _) in enumerate(self.memory):\n",
    "            G = 0\n",
    "            if !states_visited(state)\n",
    "        return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27670a91-3b85-49ef-8f0d-4d5260219295",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize value function arbitrarily\n",
    "# def calculate_episode_return(q,gamma,discount_reward,t):\n",
    "#     t += 1\n",
    "#     episode_return = q + (gamma**t * discount_reward)\n",
    "#     return episode_return\n",
    "def calculate_episode_return(q,gamma,n,t=0):\n",
    "    episode_return = if (t != n) q[t+1] + (gamma**t)*(calculate_episode_return(q,gamma,n,t+1)) else 0\n",
    "    return episode_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b0d2da-60fd-4ca7-9fdb-a02912432ab6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
