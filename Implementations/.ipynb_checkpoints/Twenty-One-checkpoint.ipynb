{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33c05006-555a-4363-83ef-f4d0bfb6169d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.2000, 4.0000])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "m = torch.Tensor([2.2,4.0],)\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1e3e4e6-f2b5-4ec9-9ee9-d9ea9370e3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize policy to be evaluated\n",
    "class Agent():\n",
    "    def __init__(self, gamma=0.99):\n",
    "        #discount factor\n",
    "        self.gamma = gamma\n",
    "        #estimates of states' values\n",
    "        self.V = {}\n",
    "        #state/action spaces\n",
    "        self.state_spaces = {\n",
    "            #possible sums of cards\n",
    "            \"sum\":[i for i in range(4,22)],\n",
    "            #possible cards in dealer's hand\n",
    "            \"dealer_show_card\":[i+1 for i in range(10)],\n",
    "            #useable ace?\n",
    "            \"ace_eleven\":[False,True],\n",
    "            # #hit (or stay)?\n",
    "            # \"hit\":[0,1]\n",
    "        }\n",
    "        #hit (or stay)?\n",
    "        self.action_space = [0,1]\n",
    "        #combinations of parameters\n",
    "        self.states = []\n",
    "        #returns\n",
    "        self.rewards = {}\n",
    "        #has agent visited state before?\n",
    "        self.states_visited = {}\n",
    "        #states already encountered/returns already received\n",
    "        self.memory = []\n",
    "        \n",
    "        self.init_vals()\n",
    "        \n",
    "    def init_vals(self):\n",
    "        for total in self.state_spaces[\"sum\"]:\n",
    "            for card in self.state_spaces[\"dealer_show_card\"]:\n",
    "                for ace in self.state_spaces[\"ace_eleven\"]:\n",
    "                    self.V[(total, card, ace)] = 0\n",
    "                    self.rewards[(total, card, ace)] = []\n",
    "                    self.states_visited[(total, card, ace)] = False\n",
    "                    self.states.append((total, card, ace))\n",
    "                    \n",
    "    def policy(self, state):\n",
    "        total, _, _ = state\n",
    "        #stay if under 21, otherwise hit\n",
    "        action = 0 if total >= 20 else 1\n",
    "        return action\n",
    "        \n",
    "    def update_V(self):\n",
    "        for idt, (state, _) in enumerate(self.memory):\n",
    "            G = 0\n",
    "            if not self.states_visited[state]:\n",
    "                self.states_visited[state] = True\n",
    "                #initialize discount factor, k, for gamma^k\n",
    "                discount = 1\n",
    "                \n",
    "                for t, (_, reward) in enumerate(self.memory[idt:]):\n",
    "                    G += reward * discount\n",
    "                    discount *= self.gamma\n",
    "                    self.rewards[state].append(G)\n",
    "                    \n",
    "        for state,_ in self.memory:\n",
    "            self.V[state] = np.mean(self.rewards[state])\n",
    "            \n",
    "        for state in self.states:\n",
    "            self.states_visited[state] = False\n",
    "            \n",
    "        self.memory = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27670a91-3b85-49ef-8f0d-4d5260219295",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6b0d2da-60fd-4ca7-9fdb-a02912432ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#main\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87ed44b0-45dc-4d15-adff-40b1a01b59ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting episode 0...\n",
      "Starting episode 50000...\n",
      "Starting episode 100000...\n",
      "Starting episode 150000...\n",
      "Starting episode 200000...\n",
      "Starting episode 250000...\n",
      "Starting episode 300000...\n",
      "Starting episode 350000...\n",
      "Starting episode 400000...\n",
      "Starting episode 450000...\n",
      "0.9755244755244755\n",
      "-0.19190970832904883\n"
     ]
    }
   ],
   "source": [
    "episodes = 500000\n",
    "\n",
    "env = gym.make('Blackjack-v1')\n",
    "agent = Agent()\n",
    "\n",
    "#traverse episodes\n",
    "for i in range(episodes):\n",
    "    if i % 50000 == 0:\n",
    "        print(\"Starting episode {}...\".format(i))\n",
    "        \n",
    "    #initialize state\n",
    "    state_null = env.reset()\n",
    "    done = False\n",
    "    \n",
    "    while not done:\n",
    "        #get action, a, from state\n",
    "        action = agent.policy(state_null)\n",
    "        #get reward, q, from state action\n",
    "        state_prime, reward, done, info = env.step(action)\n",
    "        #store results\n",
    "        agent.memory.append((state_null, reward))\n",
    "        #move on to next state\n",
    "        state_null = state_prime\n",
    "        \n",
    "    #update value function\n",
    "    agent.update_V()\n",
    "\n",
    "print(agent.V[(21, 3, True)])\n",
    "print(agent.V[(4, 1, False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960c4f04-9511-4748-b956-42eced2dbbd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
