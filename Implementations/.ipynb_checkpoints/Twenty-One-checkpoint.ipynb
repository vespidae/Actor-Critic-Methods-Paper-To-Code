{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33c05006-555a-4363-83ef-f4d0bfb6169d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Python39\\lib\\site-packages\\numpy\\.libs\\libopenblas.QVLO2T66WEPI7JZ63PS3HMOHFEY472BC.gfortran-win_amd64.dll\n",
      "C:\\Python39\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# m = torch.Tensor([2.2,4.0],)\n",
    "# print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1e3e4e6-f2b5-4ec9-9ee9-d9ea9370e3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize policy to be evaluated\n",
    "class VAgent():\n",
    "    def __init__(self, gamma=0.99):\n",
    "        #discount factor\n",
    "        self.gamma = gamma\n",
    "        #estimates of states' values (total discounted rewards: https://datascience.stackexchange.com/questions/9832/what-is-the-q-function-and-what-is-the-v-function-in-reinforcement-learning)\n",
    "        self.V = {}\n",
    "        #state/action spaces\n",
    "        self.state_spaces = {\n",
    "            #possible sums of cards\n",
    "            \"sum\":[i for i in range(4,22)],\n",
    "            #possible cards in dealer's hand\n",
    "            \"dealer_show_card\":[i+1 for i in range(10)],\n",
    "            #useable ace?\n",
    "            \"ace_eleven\":[False,True],\n",
    "            # #hit (or stay)?\n",
    "            # \"hit\":[0,1]\n",
    "        }\n",
    "        #hit (or stay)?\n",
    "        self.action_space = [0,1]\n",
    "        #combinations of parameters\n",
    "        self.states = []\n",
    "        #state returns\n",
    "        self.rewards = {}\n",
    "        #has agent visited state before?\n",
    "        self.states_visited = {}\n",
    "        #states already encountered, returns already received\n",
    "        self.memory = []\n",
    "        \n",
    "        self.init_vals()\n",
    "        \n",
    "    def init_vals(self):\n",
    "        for total in self.state_spaces[\"sum\"]:\n",
    "            for card in self.state_spaces[\"dealer_show_card\"]:\n",
    "                for ace in self.state_spaces[\"ace_eleven\"]:\n",
    "                    for hit in self.action_space:\n",
    "                        self.V[(total, card, ace)] = 0\n",
    "                        self.rewards[(total, card, ace)] = []\n",
    "                        self.states_visited[(total, card, ace)] = False\n",
    "                        self.states.append((total, card, ace))\n",
    "                    \n",
    "    def policy(self, state):\n",
    "        total, _, _ = state\n",
    "        #stay if under 21, otherwise hit\n",
    "        action = 0 if total >= 20 else 1\n",
    "        return action\n",
    "        \n",
    "    def update_V(self):\n",
    "        for idt, (state, _) in enumerate(self.memory):\n",
    "            G = 0\n",
    "            if not self.states_visited[state]:\n",
    "                self.states_visited[state] = True\n",
    "                #initialize discount factor, k, for gamma^k\n",
    "                discount = 1\n",
    "                \n",
    "                for t, (_, reward) in enumerate(self.memory[idt:]):\n",
    "                    G += reward * discount\n",
    "                    discount *= self.gamma\n",
    "                    self.rewards[state].append(G)\n",
    "                    \n",
    "        for state,_ in self.memory:\n",
    "            self.V[state] = np.mean(self.rewards[state])\n",
    "            \n",
    "        for state in self.states:\n",
    "            self.states_visited[state] = False\n",
    "            \n",
    "        self.memory = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27670a91-3b85-49ef-8f0d-4d5260219295",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize policy to be evaluated\n",
    "class QAgent():\n",
    "    def __init__(self, epsilon=0.1, gamma=0.99):\n",
    "        #proportion of time agent will take off-greedy action\n",
    "        self.epsilon = epsilon\n",
    "        #discount factor\n",
    "        self.gamma = gamma\n",
    "        #policy per state\n",
    "        self.policy = {}\n",
    "        #estimates of actions' values (expected return per action)\n",
    "        self.Q = {}\n",
    "        #state/action spaces\n",
    "        self.state_subspaces = {\n",
    "            #possible sums of cards\n",
    "            \"sum\":[i for i in range(4,22)],\n",
    "            #possible cards in dealer's hand\n",
    "            \"dealer_show_card\":[i+1 for i in range(10)],\n",
    "            #useable ace?\n",
    "            \"ace_eleven\":[False,True],\n",
    "            # #hit (or stay)?\n",
    "            # \"hit\":[0,1]\n",
    "        }\n",
    "        #hit (or stay)?\n",
    "        self.action_space = [0,1]\n",
    "        #combinations of states\n",
    "        self.state_space = []\n",
    "        #action returns\n",
    "        self.returns = {}\n",
    "        #has agent visited state-action pair before?\n",
    "        self.pairs_visited = {}\n",
    "        #pairs already encountered, returns already received\n",
    "        self.memory = []\n",
    "        \n",
    "        self.init_vals()\n",
    "        self.init_policy()\n",
    "        \n",
    "    def init_vals(self):\n",
    "        for total in self.state_subspaces[\"sum\"]:\n",
    "            for card in self.state_subspaces[\"dealer_show_card\"]:\n",
    "                for ace in self.state_subspaces[\"ace_eleven\"]:\n",
    "                    state = (total, card, ace)\n",
    "                    self.state_space.append(state)\n",
    "                    for action in self.action_space:\n",
    "                        self.Q[(state, action)] = 0\n",
    "                        self.returns[(state, action)] = []\n",
    "                        self.pairs_visited[(state, action)] = False\n",
    "                    \n",
    "    def init_policy(self):\n",
    "        policy = {}\n",
    "        n = len(self.action_space)\n",
    "        for state in self.state_space:\n",
    "            policy[state] = [1/n for _ in range(n)]\n",
    "        self.policy = policy\n",
    "        \n",
    "    def choose_action(self, state):\n",
    "        action = np.random.choice(self.action_space, p=self.policy[state])\n",
    "        return action\n",
    "        \n",
    "    def update_Q(self):\n",
    "        for idt, (state, action, _) in enumerate(self.memory):\n",
    "            G = 0\n",
    "            #initialize discount factor, k, for gamma^k\n",
    "            discount = 1\n",
    "            \n",
    "            if not self.pairs_visited[(state, action)]:\n",
    "                self.pairs_visited[(state, action)] = True\n",
    "                \n",
    "                for t, (_, _, reward) in enumerate(self.memory[idt:]):\n",
    "                    G += reward * discount\n",
    "                    discount *= self.gamma\n",
    "                    self.returns[(state, action)].append(G)\n",
    "                    \n",
    "        for state, action, _ in self.memory:\n",
    "            self.Q[(state, action)] = np.mean(self.returns[(state, action)])\n",
    "            self.update_policy(state)\n",
    "            \n",
    "        for state_action in self.pairs_visited.keys():\n",
    "            self.pairs_visited[state_action] = False        \n",
    "            \n",
    "        self.memory = []\n",
    "        \n",
    "    def update_policy(self, state):\n",
    "        actions = [self.Q[(state, a)] for a in self.action_space]\n",
    "        a_max = np.argmax(actions)\n",
    "        n_actions = len(self.action_space)        \n",
    "        probabilities = []\n",
    "        \n",
    "        for action in self.action_space:\n",
    "            probability = 1 - self.epsilon + self.epsilon / n_actions if action == a_max else self.epsilon / n_actions\n",
    "            probabilities.append(probability)\n",
    "        self.policy[state] = probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6b0d2da-60fd-4ca7-9fdb-a02912432ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#main\n",
    "import gym\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87ed44b0-45dc-4d15-adff-40b1a01b59ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting episode 0: win rate = 0.0\n",
      "Starting episode 50000: win rate = 0.42146\n",
      "Starting episode 100000: win rate = 0.42171\n",
      "Starting episode 150000: win rate = 0.42192\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "(21, 3, True)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8516/3042756873.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mQ\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m21\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mQ\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: (21, 3, True)"
     ]
    }
   ],
   "source": [
    "episodes = 200000\n",
    "win_lose_draw = {-1:0, 0:0, 1:0}\n",
    "win_rates = []\n",
    "\n",
    "agent = QAgent(epsilon = 0.001)\n",
    "env = gym.make('Blackjack-v1')\n",
    "\n",
    "#traverse episodes\n",
    "for i in range(episodes):\n",
    "    if i > 0 and i % 1000 == 0:\n",
    "        pct = win_lose_draw[1] / i\n",
    "        win_rates.append(pct)\n",
    "    if i % 50000 == 0:\n",
    "        rates = win_rates[-1] if win_rates else 0.0\n",
    "        print(\"Starting episode {}: win rate = {}\".format(i, rates))\n",
    "        \n",
    "        \n",
    "    #initialize state\n",
    "    state_null = env.reset()\n",
    "    done = False\n",
    "    \n",
    "    while not done:\n",
    "        #get action, a, from state\n",
    "        action = agent.choose_action(state_null)\n",
    "        #get reward, q, from state action\n",
    "        state_prime, reward, done, info = env.step(action)\n",
    "        #store results\n",
    "        agent.memory.append((state_null, action, reward))\n",
    "        #move on to next state\n",
    "        state_null = state_prime\n",
    "        env.render()\n",
    "        \n",
    "    #update value function\n",
    "    agent.update_Q()\n",
    "    \n",
    "    win_lose_draw[reward] += 1\n",
    "    \n",
    "plt.plot(win_rates)\n",
    "plt.show()\n",
    "\n",
    "# print(agent.V[(21, 3, True)])\n",
    "# print(agent.V[(4, 1, False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960c4f04-9511-4748-b956-42eced2dbbd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
